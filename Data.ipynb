{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f183758",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clarity./Desktop/Columbia/FALL 2025/STAT 5025/Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pgeocode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2b910b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token loaded: True\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "print(\"Token loaded:\", bool(os.getenv(\"app_token\")))\n",
    "app_token = os.getenv(\"app_token\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b65e5c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_nyc_dataset(dataset_id, limit=1000000):\n",
    "    base_url = f\"https://data.cityofnewyork.us/resource/{dataset_id}.json\"\n",
    "    headers = {\"app_token\": app_token} if app_token else {}\n",
    "    params = {\"$limit\": limit}\n",
    "\n",
    "    response = requests.get(base_url, headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    df = pd.DataFrame(response.json())\n",
    "    print(f\"Retrieved {len(df)} rows and {len(df.columns)} columns\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6655120e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 591 rows and 32 columns\n",
      "Retrieved 80 rows and 18 columns\n",
      "Retrieved 80 rows and 18 columns\n",
      "Retrieved 24681 rows and 19 columns\n",
      "Retrieved 24681 rows and 19 columns\n",
      "Retrieved 2054 rows and 34 columns\n",
      "Retrieved 2054 rows and 34 columns\n"
     ]
    }
   ],
   "source": [
    "dataset_ids = {\n",
    "    'rodent': \"p937-wjvj\",\n",
    "    'food_scrap': \"if26-z6xq\",\n",
    "    'garage': \"xw3j-2yxf\",\n",
    "    'litter_basket': \"8znf-7b2c\",\n",
    "    'parks': \"enfh-gkve\"}\n",
    "\n",
    "food_scrap_df = fetch_nyc_dataset(dataset_id = dataset_ids.get('food_scrap'))\n",
    "garage_df = fetch_nyc_dataset(dataset_id = dataset_ids.get('garage'))\n",
    "litter_basket_df = fetch_nyc_dataset(dataset_id = dataset_ids.get('litter_basket'))\n",
    "parks_df = fetch_nyc_dataset(dataset_id = dataset_ids.get('parks'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1452d0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- RAT INSPECTION PORTAL (RIP) DATA ----- #\n",
    "dataset_id = \"p937-wjvj\"\n",
    "url = f\"https://data.cityofnewyork.us/resource/{dataset_id}.json\"\n",
    "\n",
    "headers = {\"app_token\": app_token}\n",
    "params = {\n",
    "    '$limit': 1000000,\n",
    "    '$where': \"inspection_date >= '2023-01-01T00:00:00' AND inspection_date < '2024-01-01T00:00:00' AND inspection_type='Initial'\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers, params=params)\n",
    "rat_df = pd.DataFrame(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4fd1e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- POPULATION DATA ----- #\n",
    "url = \"https://api.census.gov/data/2022/acs/acs5\"\n",
    "\n",
    "params = {\n",
    "    'get': 'NAME,B01003_001E',\n",
    "    'for': 'zip code tabulation area:*',\n",
    "    #'key': CENSUS_KEY\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=params, timeout=30)\n",
    "data = response.json()\n",
    "df = pd.DataFrame(data[1:], columns=data[0])\n",
    "df.columns = ['name', 'population', 'ZIP']\n",
    "\n",
    "# Filtering for NYC zip codes\n",
    "pop_df = df[df['ZIP'].str.startswith(('100', '101', '102', '103', '104', \n",
    "    '111', '112', '113', '114', '116'))].reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724f1784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip_code</th>\n",
       "      <th>inspections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10002</td>\n",
       "      <td>3922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003</td>\n",
       "      <td>2576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  zip_code  inspections\n",
       "0        0          297\n",
       "1    10000            1\n",
       "2    10001          182\n",
       "3    10002         3922\n",
       "4    10003         2576"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_df = rat_df.groupby('zip_code').size().reset_index(name='inspections')\n",
    "\n",
    "regression_df = regression_df.merge(\n",
    "    pop_df[['ZIP', 'population']],  # Set ZIP as index, adds only the population column\n",
    "    left_on='zip_code',\n",
    "    right_on='ZIP',  # Merge on the index instead of a column\n",
    "    how='inner' # Keep only rows with values for both inspections and population\n",
    ").drop(columns=['ZIP'])\n",
    "\n",
    "#regression_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ced3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Regression DataFrame:\")\n",
    "print(regression_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "579f874a",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Zip codes that have a DSNY garage\n",
    "zips_with_garages = set(garage_df['zip'].unique())\n",
    "\n",
    "# Adding a dummy variable: 1 if the zip code has a garage, 0 if not\n",
    "regression_df['has_garage'] = regression_df['zip_code'].isin(zips_with_garages).astype(int)\n",
    "\n",
    "# Initialize geocoder and get postal data\n",
    "geocoder = pgeocode.Nominatim('us')\n",
    "postal_df = geocoder._data_frame\n",
    "\n",
    "# Convert to numeric\n",
    "food_scrap_df['latitude'] = pd.to_numeric(food_scrap_df['latitude'], errors='coerce')\n",
    "food_scrap_df['longitude'] = pd.to_numeric(food_scrap_df['longitude'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64262a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  zip_code  inspections population  has_garage  has_dropoff\n",
      "0    10001          182      27004           0            1\n",
      "1    10002         3922      76518           1            1\n",
      "2    10003         2576      53877           0            1\n",
      "3    10004           18       4579           0            0\n",
      "4    10005           27       8801           0            0\n",
      "182\n"
     ]
    }
   ],
   "source": [
    "# Function to find nearest ZIP\n",
    "def get_zip(lat, lon):\n",
    "    if pd.isna(lat) or pd.isna(lon):\n",
    "        return None\n",
    "\n",
    "    distances = np.sqrt(\n",
    "        (postal_df['latitude'] - lat)**2 + \n",
    "        (postal_df['longitude'] - lon)**2\n",
    "    )\n",
    "    nearest_idx = distances.idxmin()\n",
    "    return str(int(postal_df.loc[nearest_idx, 'postal_code']))\n",
    "\n",
    "# Apply to DataFrame\n",
    "food_scrap_df['zip_code'] = food_scrap_df.apply(lambda row: get_zip(row['latitude'], row['longitude']), axis=1)\n",
    "\n",
    "# Zip codes that have a DSNY garage\n",
    "zips_with_dropoffs = set(food_scrap_df['zip_code'].unique())\n",
    "\n",
    "# Adding a dummy variable: 1 if the zip code has a dropoff, 0 if not\n",
    "regression_df['has_dropoff'] = regression_df['zip_code'].isin(zips_with_dropoffs).astype(int)\n",
    "\n",
    "\n",
    "print(regression_df.head())\n",
    "print(len(regression_df))\n",
    "regression_df.to_csv('regression_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf36d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "parks_df\n",
    "parks_df = parks_df.loc[:, ['zipcode', 'acres', 'omppropid']]\n",
    "parks_df['acres'] = parks_df['acres'].astype(float)\n",
    "parks_df = parks_df.dropna(subset=['zipcode', 'acres'])\n",
    "\n",
    "parks_df['zipcode'] = parks_df['zipcode'].astype(str).str.split(',')\n",
    "parks_df = parks_df.explode('zipcode')\n",
    "\n",
    "# 3. Clean formatting and keep only valid 5-digit ZIPs\n",
    "parks_df['zipcode'] = parks_df['zipcode'].str.strip()\n",
    "\n",
    "# len(parks_df)\n",
    "# parks_df.zipcode.nunique() #183\n",
    "# parks_df.omppropid.nunique() #2052\n",
    "\n",
    "parks_df['num_zips'] = parks_df['zipcode'].apply(lambda x: len(str(x).split(',')))\n",
    "parks_df['num_zips'].value_counts().head()\n",
    "parks_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5345ed04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>total_park_acres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1247.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>14.561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>90.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>13.712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>23.624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  zipcode  total_park_acres\n",
       "0       1          1247.912\n",
       "1   10001            14.561\n",
       "2   10002            90.192\n",
       "3   10003            13.712\n",
       "4   10004            23.624"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf = parks_df.groupby('zipcode')\n",
    "park_size_df = gdf['acres'].sum().reset_index(name='total_park_acres')\n",
    "park_size_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b0b44573",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_with_parks = regression_df.merge(\n",
    "    park_size_df,\n",
    "    left_on='zip_code',\n",
    "    right_on='zipcode',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "regression_with_parks.head()\n",
    "regression_with_parks.to_csv('regression_with_parks.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc7d5b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
